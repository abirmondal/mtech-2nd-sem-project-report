The work by Tambwekar et al. \cite{tambwekar_controllable_2018} addresses controllable neural story plot generation, specifically focusing on goal-directed story generation by guiding a recurrent neural network towards a specified final state using reinforcement learning and reward shaping. Their reward function incorporated a distance component measuring proximity to the goal event and a story-verb frequency component based on corpus analysis, rewarding progress towards a goal verb cluster. Using a seq2seq language model or an LSTM-based model trained on event abstractions represented as tuples (e.g., <s, v, o, m>), their method achieved a high goal attainment rate exceeding 93\% and improved subjective coherence ratings. However, a significant limitation is that the generated event tuples are not human-readable, necessitating an additional "event-to-sentence" or "story realisation" step to produce natural language sentences. This two-stage pipeline can be lossy, potentially undermining coherence gains during translation, especially if generated events are out-of-distribution for the sentence generator.