The work by Martin et al. \cite{martin_event_2018}, presented at the Thirty-Second AAAI Conference on Artificial Intelligence, introduces a method for automated story generation that utilises event representations as a means to handle the significant sparsity inherent in textual story corpora \cite{martin_event_2018}. Recognising that individual sentences in stories are often unique, making word or sentence-level analysis challenging for coherence beyond short sequences, their approach defines an event as a unit that creates a change in the story world's state. Formally, they represent an event as a tuple containing a subject, verb, direct object, and additional disambiguation token(s), comparing this to other representations like that by Pichotta and Mooney \cite{pichotta_learning_2016}. This event representation aims to increase the potential overlap of events across stories and the number of examples a learning system observes, thereby reducing sparsity and aiding predictive ability. To generate stories, they employ Deep Neural Nets, specifically a recurrent neural network, trained on these sequences of events to predict story continuations. The resulting sequence of events from this "event-to-event" system can then be expanded into natural language sentences by a separate "story realisation" or "event-to-sentence" component. This approach leverages a semantic abstraction to learn structural patterns of stories, potentially enabling the generation of novel event sequences resembling coherent narratives.