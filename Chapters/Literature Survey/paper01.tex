An approach to learning statistical scripts focused on using multi-argument events \cite{pichotta_statistical_2014}. This involved developing a 4-tuple event representation, notably without prepositions in this particular iteration. The methodology incorporated coreference information, leveraging tools like the Stanford coreference resolution engine, between event arguments to encode pairwise entity relationships and model interactions, which facilitated the generation of event chains for stories. The key statistical model employed was the 2D rewritten all-bigram model. Training was conducted using a dataset of approximately 1.1 million articles from the NYT portion of the Gigaword Corpus. A limitation noted is that the complexity of this structured representation adds to the statistical model's complexity. Evaluation utilised the Narrative Cloze, assessing performance via metrics such as Recall at 25, Verb recall at 25, and 4-Tuple recall at 25. Their model achieved results, making it the best-performing published system on this evaluation at the time. While the sources describe the system's successful performance and approach, they do not explicitly state the specific conclusion presented within the 2014 paper.