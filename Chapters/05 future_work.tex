\chapter{Future Work}

The advancements in automatic story generation have demonstrated the efficacy of various approaches, including neural models, event representations, and human-AI collaboration frameworks. However, challenges related to coherence, creativity, and long-form narrative generation remain open research problems.

In future work, we aim to explore story generation leveraging event-based and graph-based representations. Event-based models, which structure narratives through event sequences, have shown significant promise in maintaining logical flow and enhancing coherence in generated stories. Recent research suggests that event-driven approaches, such as event-to-event and event-to-sentence frameworks, reduce data sparsity and improve semantic alignment within generated texts. Moreover, event abstraction enables structured learning, allowing models to generalise more effectively across various storytelling contexts.

Complementary to event-based methods, graph-based representations offer a structured approach to modelling narrative progression. Graph-based event planning frameworks utilise dependencies between key story elements, facilitating controlled and goal-directed story generation. These frameworks allow for explicit representations of narrative arcs, character relationships, and causal dependencies, improving the consistency and logical progression of generated stories. Given that long-form generation often suffers from loss of coherence over extended sequences, integrating graph-based event planning mechanisms can mitigate these issues by enforcing structured dependencies.

By combining event and graph representations, we aim to improve coherence, maintain engaging storytelling arcs, and develop a scalable framework for automatic story generation. Our future research will focus on refining these models, evaluating their effectiveness in long-form storytelling, and developing methodologies to enhance creativity while preserving logical consistency.
